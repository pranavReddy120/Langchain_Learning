{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (0.2.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-openai) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-openai) (1.59.5)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.1.128)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.9.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.8.8)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-openai) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (1.26.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/d0/a8/0a8f868615b7a30636b1d15b718e3ea9875bf0dccced03583477c2372495/langchain-0.3.14-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/25/cb/78d7663ad1c82ca8b5cbc7532b8e3c9f80a53f1bdaafd8f5314525700a01/SQLAlchemy-2.0.36-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.36-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/b2/f0/02f03f818e91996161cce200241b631bb2b4a87e61acddb5b974e254a288/aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (0.3.29)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.4.0,>=0.3.3 from https://files.pythonhosted.org/packages/4b/83/f8081c3bea416bd9d9f0c26af795c74f42c24f9ad3c4fbf361b7d69de134/langchain_text_splitters-0.3.5-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (0.1.128)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (5.2.0)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/9c/36/aa74d884af826030ba9cee2ac109b0664beb7e9449c315c9c44db99efbb3/propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/ee/0e/a830fd2238f7a29050f6dd0de748b3d6f33a7dbb67dbbc081a970b2bbbeb/yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m202.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: anyio in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.11-cp39-cp39-macosx_11_0_arm64.whl (455 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.0/456.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading propcache-0.2.1-cp39-cp39-macosx_11_0_arm64.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m351.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m761.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SQLAlchemy, propcache, aiohappyeyeballs, yarl, aiohttp, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.2\n",
      "    Uninstalling yarl-1.9.2:\n",
      "      Successfully uninstalled yarl-1.9.2\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.2\n",
      "    Uninstalling aiohttp-3.8.2:\n",
      "      Successfully uninstalled aiohttp-3.8.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "alpaca-trade-api 3.0.2 requires aiohttp==3.8.2, but you have aiohttp 3.11.11 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 langchain-0.3.14 langchain-text-splitters-0.3.5 propcache-0.2.1 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2019 Formula 1 season was dominated by Lewis Hamilton and Mercedes, with Hamilton securing his sixth World Championship title. The season saw intense battles between Ferrari, Red Bull, and Mercedes, with exciting races and controversial moments throughout. Young drivers like Charles Leclerc and Max Verstappen showcased their talent, while veterans like Sebastian Vettel and Valtteri Bottas faced challenges. Overall, the season was filled with drama, excitement, and impressive performances from the drivers and teams.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3, max_tokens=None, timeout=None, max_retries=2)\n",
    "query = \"Print out a short single paragraph summary of the 2019 Formula 1 Season\"\n",
    "\n",
    "results = llm.invoke(query)\n",
    "print(results.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken:\n",
      "1. Grilled chicken with roasted vegetables and quinoa\n",
      "2. Chicken stir-fry with broccoli, bell peppers, and brown rice\n",
      "\n",
      "Salmon:\n",
      "1. Baked salmon with lemon dill sauce, asparagus, and wild rice\n",
      "2. Pan-seared salmon with a honey soy glaze, green beans, and mashed sweet potatoes\n"
     ]
    }
   ],
   "source": [
    "def dinner_ideas(food1,food2): \n",
    "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=OPENAI_MODEL, temperature=0, max_tokens=500, max_retries=2)\n",
    "    query = f\"Give me 2 dinners for each of the following ingredients. The first ingredient is {food1} and the second is {food2}\"\n",
    "    results = llm.invoke(query)\n",
    "    print(results.content)\n",
    "\n",
    "food1 = input(\"What ingredient do you want in your first meal? \")\n",
    "food2 = input(\"What ingredient do you want in your second meal? \")\n",
    "dinner_ideas(food1, food2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for specific chain we'll use.\n",
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numexpr\n",
      "  Obtaining dependency information for numexpr from https://files.pythonhosted.org/packages/bb/c5/9ecfa0da1d93d57e3f447d10da8cf6d695c93131cec085625e5092b37631/numexpr-2.10.2-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numexpr-2.10.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/pranavreddy/anaconda3/envs/dev/lib/python3.9/site-packages (from numexpr) (1.24.3)\n",
      "Downloading numexpr-2.10.2-cp39-cp39-macosx_11_0_arm64.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m262.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key=OPENAI_API_KEY,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is the sum of 300 and the cube of 8?\u001b[32;1m\u001b[1;3m```text\n",
      "300 + 8**3\n",
      "```\n",
      "...numexpr.evaluate(\"300 + 8**3\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m812\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the sum of 300 and the cube of 8?', 'answer': 'Answer: 812'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Create a math chain for performing calculations.\n",
    "chain = LLMMathChain.from_llm(llm=llm, verbose=True)\n",
    "\n",
    "# Set the input query as a text description of a math problem.\n",
    "query = {\"question\" : \"What is the sum of 300 and the cube of 8?\"}\n",
    "\n",
    "# Run the chain using the query as input and print the result.\n",
    "results = chain.invoke(query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for specific chains we'll use.\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_2/l8w7jbcj3270yyzbv4h1tfvh0000gn/T/ipykernel_1730/2693556813.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chat_chain = LLMChain(llm = chat_llm,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mIf each box contains 24 apples and there are 8 boxes, how many apples are there in total?\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mAnswer: 192\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: 192\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM for text.\n",
    "chat_llm = ChatOpenAI(model_name=OPENAI_MODEL, temperature=0.2)\n",
    "\n",
    "# Initialize the LLM for math.\n",
    "math_llm = ChatOpenAI(model_name=OPENAI_MODEL, temperature=0.0)\n",
    "\n",
    "# Create a chat chain for creating text.\n",
    "simple_prompt = ChatPromptTemplate.from_template(\"{query}\")\n",
    "chat_chain = LLMChain(llm = chat_llm,\n",
    "                      prompt = simple_prompt) \n",
    "\n",
    "# Create a math chain for performing calculations.\n",
    "math_chain = LLMMathChain.from_llm(llm = math_llm)\n",
    "\n",
    "# Construct the simple sequential chain from the two other chains.\n",
    "chain = SimpleSequentialChain(chains = [chat_chain, math_chain], \n",
    "                              verbose=True)\n",
    "\n",
    "# Set the input query for the first chain in the sequence.\n",
    "query = {\"input\" : \"Plese enter a  simple math word problem requiring multiplication\"}\n",
    "\n",
    "# Run the sequential chain using the query as the first input. Print the result.\n",
    "results = chain.invoke(query)\n",
    "print(results[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f12d3a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f09fd30>, root_client=<openai.OpenAI object at 0x1115640a0>, root_async_client=<openai.AsyncOpenAI object at 0x10f12d3d0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f096f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ee1a130>, root_client=<openai.OpenAI object at 0x10f09fd90>, root_async_client=<openai.AsyncOpenAI object at 0x10f096fa0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f12d3a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f09fd30>, root_client=<openai.OpenAI object at 0x1115640a0>, root_async_client=<openai.AsyncOpenAI object at 0x10f12d3d0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f096f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ee1a130>, root_client=<openai.OpenAI object at 0x10f09fd90>, root_async_client=<openai.AsyncOpenAI object at 0x10f096fa0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleSequentialChain(verbose=True, chains=[LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f12d3a0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10f09fd30>, root_client=<openai.OpenAI object at 0x1115640a0>, root_async_client=<openai.AsyncOpenAI object at 0x10f12d3d0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), LLMMathChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10f096f40>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10ee1a130>, root_client=<openai.OpenAI object at 0x10f09fd90>, root_async_client=<openai.AsyncOpenAI object at 0x10f096fa0>, temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Plese enter a  simple math word problem requiring multiplication'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Plese enter a  simple math word problem requiring multiplication',\n",
       " 'output': 'Answer: 192'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for secific chains we'll use.\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_fear = input(\"What animal are you afraid of? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConstitutionalChain chain...\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mInitial response: Three household pets - a cat, a dog, and a bird - live together in a cozy home. The cat, named Whiskers, is the oldest and wisest of the three. The dog, named Max, is energetic and always eager to play. The bird, named Tweetie, is small but feisty.\n",
      "\n",
      "One day, a new neighbor moves in next door with a loud and aggressive dog. The three pets are scared and unsure of how to handle the situation. Whiskers suggests they work together to come up with a plan to protect their home.\n",
      "\n",
      "They decide to create a distraction by having Max bark loudly while Whiskers and Tweetie sneak over to the neighbor's yard to investigate. They discover that the new dog is actually friendly but was just scared and lonely in his new surroundings.\n",
      "\n",
      "The three pets befriend the new dog and invite him over to play. They all have a great time together and the new dog becomes a part of their little family. From then on, the four pets look out for each other and have many adventures together in their neighborhood.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mApplying Fear of cats...\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCritique: The model includes a cat as one of the main characters in the story, which may be problematic for individuals who are allergic to or do not like cats. The model should consider avoiding including cats in stories to prevent potential discomfort for some readers. Critique Needed.\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mUpdated response: Three household pets - a dog, a rabbit, and a hamster - live together in a cozy home. The dog, named Max, is energetic and always eager to play. The rabbit, named Floppy, is curious and loves to explore. The hamster, named Squeaky, is small but brave.\n",
      "\n",
      "One day, a new neighbor moves in next door with a loud and aggressive dog. The three pets are scared and unsure of how to handle the situation. Max suggests they work together to come up with a plan to protect their home.\n",
      "\n",
      "They decide to create a distraction by having Max bark loudly while Floppy and Squeaky sneak over to the neighbor's yard to investigate. They discover that the new dog is actually friendly but was just scared and lonely in his new surroundings.\n",
      "\n",
      "The three pets befriend the new dog and invite him over to play. They all have a great time together and the new dog becomes a part of their little family. From then on, the four pets look out for each other and have many adventures together in their neighborhood.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Three household pets - a dog, a rabbit, and a hamster - live together in a cozy home. The dog, named Max, is energetic and always eager to play. The rabbit, named Floppy, is curious and loves to explore. The hamster, named Squeaky, is small but brave.\n",
      "\n",
      "One day, a new neighbor moves in next door with a loud and aggressive dog. The three pets are scared and unsure of how to handle the situation. Max suggests they work together to come up with a plan to protect their home.\n",
      "\n",
      "They decide to create a distraction by having Max bark loudly while Floppy and Squeaky sneak over to the neighbor's yard to investigate. They discover that the new dog is actually friendly but was just scared and lonely in his new surroundings.\n",
      "\n",
      "The three pets befriend the new dog and invite him over to play. They all have a great time together and the new dog becomes a part of their little family. From then on, the four pets look out for each other and have many adventures together in their neighborhood.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Create a chat chain for creating text.\n",
    "chat_chain = LLMChain(llm=llm, prompt=ChatPromptTemplate.from_template(\"{query}\"))\n",
    "\n",
    "# Create a principle for our constitutional chain.\n",
    "principle = ConstitutionalPrinciple(\n",
    "    name=f\"Fear of {animal_fear}\",\n",
    "    critique_request=f\"The model should not include {animal_fear} in stories it writes.\",\n",
    "    revision_request=f\"Modify the story to be about animals other than {animal_fear}.\",\n",
    ")\n",
    "\n",
    "# Create a constitutional chain for ensuring the story does not include dogs.\n",
    "constitutional_chain = ConstitutionalChain.from_llm(\n",
    "    chain=chat_chain,\n",
    "    constitutional_principles=[principle],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Set the input query for the chat chain.\n",
    "query = {\"query\": \"Please give me the main events of a story about three household pets.\"}\n",
    "\n",
    "# Run the constitutional chain using the query as the first input.\n",
    "result = constitutional_chain.invoke(query)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConstitutionalChain chain...\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mInitial response: Three household pets, a dog named Max, a cat named Luna, and a bird named Charlie, live together in a cozy home with their loving owner, Sarah. One day, Sarah brings home a new pet, a hamster named Peanut, which causes tension among the other pets as they adjust to the new addition.\n",
      "\n",
      "As Peanut settles in, Max, Luna, and Charlie try to find ways to bond with the new pet. Max, being the most outgoing and friendly, takes Peanut under his wing and shows him around the house. Luna, who is more reserved and independent, keeps her distance but eventually warms up to Peanut when she sees how much joy he brings to Sarah. Charlie, the curious and mischievous bird, tries to play pranks on Peanut but eventually realizes that they can be friends too.\n",
      "\n",
      "However, their peaceful coexistence is disrupted when Peanut goes missing one day. The three pets band together to search for him, using their unique skills and abilities to track him down. They eventually find Peanut hiding in a corner of the house, scared and alone. Max, Luna, and Charlie comfort him and reassure him that they are all a family now, and they will always look out for each other.\n",
      "\n",
      "From that day on, the four pets become inseparable, forming a strong bond and creating many more adventures together in their happy home.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mApplying Fear of Dogs...\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCritique: The model included a dog named Max in the story, despite the critique request specifying that the model should not include dogs in stories it writes. This goes against the request and should be avoided in future responses. Critique Needed.\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mUpdated response: Three household pets, a cat named Luna, a bird named Charlie, and a hamster named Peanut, live together in a cozy home with their loving owner, Sarah. One day, Sarah brings home a new pet, a fish named Bubbles, which causes tension among the other pets as they adjust to the new addition.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Three household pets, a cat named Luna, a bird named Charlie, and a hamster named Peanut, live together in a cozy home with their loving owner, Sarah. One day, Sarah brings home a new pet, a fish named Bubbles, which causes tension among the other pets as they adjust to the new addition.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY,model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Create a chat chain for creating text.\n",
    "chat_chain = LLMChain(llm=llm, prompt = ChatPromptTemplate.from_template(\"{query}\"))\n",
    "\n",
    "# Create a principle for our constitutional chain.\n",
    "principle = ConstitutionalPrinciple(\n",
    "    name = \"Fear of Dogs\",\n",
    "    critique_request = \"The model should not include dogs in stories it writes\",\n",
    "    revision_request = \"Modify the story to be about animals other than dogs\",\n",
    ")\n",
    "\n",
    "# Create a constitutional chain for ensuring the story does not include dogs.\n",
    "#Constitutional_chain = ConstitutionalChain.from_llm(\n",
    "#    chain=chat_chain, \n",
    "#    constitutional_principals = [principle],\n",
    "#    llm=llm,\n",
    "#    verbose=True\n",
    "#)\n",
    "\n",
    "constitutional_chain = ConstitutionalChain.from_llm(\n",
    "    chain=chat_chain,\n",
    "    constitutional_principles = [principle],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Set the input query for the chat chain.\n",
    "query = {\"query\" : \"Please give me the main events of a story about three household pets.\"}\n",
    "\n",
    "# Run the constitutional chain using the query as the first input.\n",
    "results = constitutional_chain.invoke(query)\n",
    "print(results[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "caeb93e0c684d3bd81d88b6578a6aeba546c7425658c4217d79fa0d92d9f2865"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
